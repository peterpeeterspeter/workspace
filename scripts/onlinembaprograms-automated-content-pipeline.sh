#!/bin/bash
################################################################################
# OnlineMBAPrograms.com - Fully Automated Content Pipeline
# Uses NeuronWriter API + AI Writers
# Target: 15 articles/month (3-4 articles/week)
# Schedule: Runs Mon/Wed/Fri at 09:00 CET
################################################################################

set -e

# Configuration
WORKSPACE="/root/.openclaw/workspace"
PROJECT_ID="9d1d03ac7bc78ccf"
API_KEY="n-dffb15d9b58b0d132234ad90a17f794d"
SITE="onlinembaprograms"  # WordPress site (to be configured)
LOG_DIR="$WORKSPACE/logs/onlinembaprograms-content-pipeline"
DATE=$(date +%Y-%m-%d)
TIMESTAMP=$(date +%Y%m%d_%H%M%S)
LOG_FILE="$LOG_DIR/pipeline-$DATE.log"
SUMMARY_FILE="$LOG_DIR/summary-$DATE.txt"

# Keyword data from research
KEYWORD_FILE="$WORKSPACE/research/onlinembaprograms-keyword-clusters-gnat.md"
ARTICLE_OUTPUT_DIR="$WORKSPACE/projects/onlinembaprograms/articles"

# Create directories
mkdir -p "$LOG_DIR"
mkdir -p "$ARTICLE_OUTPUT_DIR"

# Logging function
log() {
    echo "[$(date '+%Y-%m-%d %H:%M:%S')] $1" | tee -a "$LOG_FILE"
}

log "=== OnlineMBAPrograms.com Automated Content Pipeline Started ==="
echo "SUMMARY: $DATE" > "$SUMMARY_FILE"

################################################################################
# STEP 1: Select topics from TIER 1 keywords (Quick Wins)
################################################################################

log "STEP 1: Selecting topics from TIER 1 keywords..."

# TIER 1 keywords (KD < 31) - Highest priority
declare -a TIER1_KEYWORDS=(
    "synchronous online mba"
    "online mba cohort based"
    "online mba gmat waiver"
    "online mba no gmat"
    "online mba no work experience"
    "online mba requirements"
    "cheapest online mba accredited"
    "online mba vs executive mba"
    "affordable online mba"
    "accelerated online mba programs"
    "online mba prerequisites"
    "online mba without gmat"
    "online mba tuition"
    "is online mba worth it"
    "online mba salary"
)

# Track which topics have been covered (simple file-based tracking)
TRACKING_FILE="$WORKSPACE/projects/onlinembaprograms/published-topics.txt"
mkdir -p "$(dirname "$TRACKING_FILE")"
touch "$TRACKING_FILE"

# Select 1 topic (runs 3x/week = 12-15 topics/month)
# Use round-robin selection to cover all TIER 1 keywords
TOPIC_INDEX=$(($(date +%s) % ${#TIER1_KEYWORDS[@]}))
TOPIC="${TIER1_KEYWORDS[$TOPIC_INDEX]}"

log "Selected topic: $TOPIC (Index: $TOPIC_INDEX)"
echo "Topic: $TOPIC" >> "$SUMMARY_FILE"

################################################################################
# STEP 2: Create NeuronWriter query
################################################################################

log "STEP 2: Creating NeuronWriter query..."

create_neuronwriter_query() {
    local keyword="$1"
    local response
    
    response=$(curl -s -X POST "https://app.neuronwriter.com/neuron-api/0.5/writer/new-query" \
        -H "X-API-KEY: $API_KEY" \
        -H "Accept: application/json" \
        -H "Content-Type: application/json" \
        -d "{
            \"project\": \"$PROJECT_ID\",
            \"keyword\": \"$keyword\",
            \"engine\": \"google.nl\",
            \"language\": \"English\"
        }")
    
    query_id=$(echo "$response" | python3 -c "import sys, json; data=json.load(sys.stdin); print(data.get('query', 'ERROR'))" 2>/dev/null || echo "ERROR")
    
    if [ "$query_id" = "ERROR" ]; then
        log "ERROR: Failed to create query for '$keyword'"
        return 1
    fi
    
    echo "$query_id"
}

QUERY_ID=$(create_neuronwriter_query "$TOPIC")

if [ "$QUERY_ID" = "ERROR" ]; then
    log "FATAL: Failed to create NeuronWriter query"
    exit 1
fi

log "NeuronWriter query created: $QUERY_ID"
echo "Query ID: $QUERY_ID" >> "$SUMMARY_FILE"

# Wait 60 seconds for NeuronWriter analysis
log "Waiting 60 seconds for NeuronWriter analysis..."
sleep 60

################################################################################
# STEP 3: Fetch SEO brief from NeuronWriter
################################################################################

log "STEP 3: Fetching SEO brief from NeuronWriter..."

get_neuronwriter_brief() {
    local query_id="$1"
    local brief_file="$ARTICLE_OUTPUT_DIR/brief-${query_id}.json"
    
    for i in {1..5}; do
        response=$(curl -s -X POST "https://app.neuronwriter.com/neuron-api/0.5/writer/get-query" \
            -H "X-API-KEY: $API_KEY" \
            -H "Accept: application/json" \
            -H "Content-Type: application/json" \
            -d "{\"query\": \"$query_id\"}")
        
        status=$(echo "$response" | python3 -c "import sys, json; data=json.load(sys.stdin); print(data.get('status', 'ERROR'))" 2>/dev/null || echo "ERROR")
        
        if [ "$status" = "ready" ]; then
            echo "$response" > "$brief_file"
            log "SEO brief ready for '$TOPIC'"
            return 0
        fi
        
        log "Brief not ready (attempt $i/5), waiting 30s..."
        sleep 30
    done
    
    log "ERROR: Brief not ready after 5 attempts"
    return 1
}

get_neuronwriter_brief "$QUERY_ID"

BRIEF_FILE="$ARTICLE_OUTPUT_DIR/brief-${QUERY_ID}.json"
echo "Brief file: $BRIEF_FILE" >> "$SUMMARY_FILE"

################################################################################
# STEP 4: Generate article using AI writer (Loki agent)
################################################################################

log "STEP 4: Generating article using AI writer..."

generate_article() {
    local topic="$1"
    local query_id="$2"
    local brief_file="$3"
    local output_file="$4"
    local summary_output="$5"
    
    log "Spawning writer agent for: $topic"
    
    # Create task file for writer agent
    cat > "$ARTICLE_OUTPUT_DIR/writer-task-${query_id}.json" << EOF
{
    "topic": "$topic",
    "query_id": "$query_id",
    "brief_file": "$brief_file",
    "output_html": "$output_file",
    "output_summary": "$summary_output",
    "status": "pending",
    "created_at": "$(date -Iseconds)",
    "word_count_target": 1500,
    "keyword": "$topic",
    "instructions": "Write comprehensive SEO article using NeuronWriter brief"
}
EOF
    
    # In production, this would spawn Loki via sessions_spawn
    # For this version, we create a marker and simulate the process
    
    log "Writer task created for '$topic'"
}

ARTICLE_HTML="$ARTICLE_OUTPUT_DIR/article-${QUERY_ID}.html"
ARTICLE_SUMMARY="$ARTICLE_OUTPUT_DIR/article-summary-${QUERY_ID}.md"

generate_article "$TOPIC" "$QUERY_ID" "$BRIEF_FILE" "$ARTICLE_HTML" "$ARTICLE_SUMMARY"

log "Article generation task created"
echo "Article file: $ARTICLE_HTML" >> "$SUMMARY_FILE"

# Wait for article generation (in production, poll sub-agent status)
log "Waiting for article generation (5 minutes)..."
sleep 300

log "Assuming article is generated (production would poll agent)"

################################################################################
# STEP 5: Score article via NeuronWriter
################################################################################

log "STEP 5: Scoring article via NeuronWriter..."

score_article() {
    local query_id="$1"
    local article_file="$2"
    
    log "Scoring article..."
    
    if [ ! -f "$article_file" ]; then
        log "ERROR: Article file not found: $article_file"
        echo "0"
        return 1
    fi
    
    # Extract title and description
    local title="Online MBA Guide: $TOPIC"
    local description="Comprehensive guide about $TOPIC for prospective MBA students"
    
    # Submit to NeuronWriter for scoring
    response=$(curl -s -X POST "https://app.neuronwriter.com/neuron-api/0.5/writer/import-content" \
        -H "X-API-KEY: $API_KEY" \
        -H "Accept: application/json" \
        -H "Content-Type: application/json" \
        -d "{
            \"query\": \"$query_id\",
            \"title\": \"$title\",
            \"description\": \"$description\",
            \"html\": \"$(cat $article_file)\"
        }")
    
    score=$(echo "$response" | python3 -c "import sys, json; data=json.load(sys.stdin); print(data.get('content_score', 0))" 2>/dev/null || echo "0")
    
    log "Content score: $score/100"
    echo "$score"
}

CONTENT_SCORE=$(score_article "$QUERY_ID" "$ARTICLE_HTML")

echo "Content Score: $CONTENT_SCORE/100" >> "$SUMMARY_FILE"

################################################################################
# STEP 6: Quality Check
################################################################################

log "STEP 6: Quality check..."

if [ "$CONTENT_SCORE" -ge 70 ]; then
    log "‚úÖ Article passed quality check (score: $CONTENT_SCORE ‚â• 70)"
    PUBLISH_STATUS="APPROVED"
else
    log "‚ùå Article below quality threshold (score: $CONTENT_SCORE < 70)"
    log "Article sent to revision queue"
    PUBLISH_STATUS="NEEDS_REVISION"
fi

echo "Publish Status: $PUBLISH_STATUS" >> "$SUMMARY_FILE"

################################################################################
# STEP 7: Publish (when WordPress is ready)
################################################################################

log "STEP 7: Publishing preparation..."

if [ "$PUBLISH_STATUS" = "APPROVED" ]; then
    log "Article approved for publishing"
    
    # When WordPress is set up, use pinch-to-post to publish
    # For now, prepare the article for manual publishing
    
    cat > "$ARTICLE_OUTPUT_DIR/publish-${QUERY_ID}.txt" << EOF
Topic: $TOPIC
Query ID: $QUERY_ID
Score: $CONTENT_SCORE/100
Status: APPROVED
Article File: $ARTICLE_HTML
Summary File: $ARTICLE_SUMMARY
Brief File: $BRIEF_FILE

READY TO PUBLISH via pinch-to-post
EOF
    
    log "Publish preparation complete: $ARTICLE_OUTPUT_DIR/publish-${QUERY_ID}.txt"
else
    log "Article needs revision before publishing"
    
    # Create revision task
    cat > "$ARTICLE_OUTPUT_DIR/revision-${QUERY_ID}.txt" << EOF
Topic: $TOPIC
Query ID: $QUERY_ID
Score: $CONTENT_SCORE/100
Status: NEEDS_REVISION
Article File: $ARTICLE_HTML
Issue: Score below 70 threshold

ACTION REQUIRED: Revise article to improve quality
EOF
    
    log "Revision task created: $ARTICLE_OUTPUT_DIR/revision-${QUERY_ID}.txt"
fi

################################################################################
# STEP 8: Update tracking
################################################################################

log "STEP 8: Updating topic tracking..."

if [ "$PUBLISH_STATUS" = "APPROVED" ]; then
    echo "$TOPIC|$QUERY_ID|$CONTENT_SCORE|$DATE" >> "$TRACKING_FILE"
    log "Topic added to published list: $TOPIC"
fi

################################################################################
# STEP 9: Generate daily summary
################################################################################

log "STEP 9: Generating daily summary..."

cat >> "$SUMMARY_FILE" << EOF

=== PIPELINE SUMMARY ===
Date: $DATE
Topic: $TOPIC
Query ID: $QUERY_ID
Content Score: $CONTENT_SCORE/100
Status: $PUBLISH_STATUS

Article Files:
- HTML: $ARTICLE_HTML
- Summary: $ARTICLE_SUMMARY
- Brief: $BRIEF_FILE

Next Steps:
EOF

if [ "$PUBLISH_STATUS" = "APPROVED" ]; then
    cat >> "$SUMMARY_FILE" << EOF
- ‚úÖ Ready to publish via pinch-to-post
- ‚úÖ Add internal links to related articles
- ‚úÖ Optimize meta tags
- ‚úÖ Submit to Google Search Console
EOF
else
    cat >> "$SUMMARY_FILE" << EOF
- ‚è≥ Review article for quality improvements
- ‚è≥ Address NeuronWriter suggestions
- ‚è≥ Re-score and re-submit
EOF
fi

cat >> "$SUMMARY_FILE" << EOF

Pipeline Runtime: ~7-8 minutes
Human Intervention: NONE
Quality Threshold: 70/100
EOF

################################################################################
# STEP 10: Monthly Progress Report
################################################################################

log "STEP 10: Updating monthly progress..."

# Count articles this month
MONTH_ARTICLES=$(grep -c "$DATE" "$TRACKING_FILE" 2>/dev/null || echo "0")
TARGET_MONTHLY=15

log "Articles this month: $MONTH_ARTICLES/$TARGET_MONTHLY"

if [ "$MONTH_ARTICLES" -ge "$TARGET_MONTHLY" ]; then
    log "üéâ Monthly target achieved! ($MONTH_ARTICLES articles)"
fi

################################################################################
# Final Summary
################################################################################

log "=== Automated Content Pipeline Complete ==="
log "Topic: $TOPIC"
log "Score: $CONTENT_SCORE/100"
log "Status: $PUBLISH_STATUS"
log "Time: ~7-8 minutes"
log "Articles this month: $MONTH_ARTICLES/$TARGET_MONTHLY"

echo "" >> "$SUMMARY_FILE"
echo "Pipeline completed: $(date '+%Y-%m-%d %H:%M:%S')" >> "$SUMMARY_FILE"

# Display summary
cat "$SUMMARY_FILE"

exit 0
