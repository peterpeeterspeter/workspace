#!/bin/bash
# Run Supabase import after scraping is complete

echo "ðŸ“‹ Supabase Import Instructions"
echo "=================================="
echo ""
echo "âš ï¸  PREREQUISITES:"
echo "   1. Wait for scraper to complete (all categories)"
echo "   2. Install Supabase CLI: npm install -g supabase"
echo "   3. Link to project: supabase link --project-ref YOUR_PROJECT_REF"
echo ""
echo "ðŸ“ STEPS:"
echo ""
echo "1. CREATE TABLE:"
echo "   psql --host=db.YOUR_PROJECT_REF.supabase.co --dbname=postgres -f supabase_schema.sql"
echo ""
echo "2. RUN IMPORT:"
echo "   python3 generate_supabase_import.py > supabase_import.sql"
echo ""
echo "3. EXECUTE IMPORT:"
echo "   psql --host=db.YOUR_PROJECT_REF.supabase.co --dbname=postgres -f supabase_import.sql"
echo ""
echo "   OR via Supabase CLI:"
echo "   supabase db execute --file supabase_import.sql"
echo ""
echo "=================================="
echo ""
echo "Files created:"
ls -lh /root/.openclaw/workspace/research/bathroom-products/{supabase_schema.sql,generate_supabase_import.py} 2>/dev/null | awk '{print "  " $9 " (" $5 ")"}'
